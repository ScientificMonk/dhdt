{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd98075",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Title: Ice divides and drainage divides** <br>\n",
    "Authors: [Dr. Bas Altena], [Prashant Pandit] <br>\n",
    "email: b.altena@uu.nl <br>\n",
    "Date: June 11, 2022 <br>\n",
    "\n",
    "---\n",
    "This research project is the part of submission of Internship assignment carried by Prashant Pandit, student of Master Spatial Engineering at **[ITC]**- Faculty of Geo-Information Science and Earth Observation, University of Twente, Enschede, the Netherlands, and submitted to the Internship provider Institute for Marine and Atmospheric research Utrecht **[(IMAU)]**, department of Physics, Utrecht University, the Netherlands. \n",
    "\n",
    "---\n",
    "[Dr. Bas Altena]:https://nl.linkedin.com/in/baasaltena/nl\n",
    "[Prashant Pandit]:https://www.linkedin.com/in/prashantpandit20/\n",
    "[ITC]:https://www.itc.nl/\n",
    "[(IMAU)]:https://www.uu.nl/en/research/institute-for-marine-and-atmospheric-research-imau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3673f97-4f0f-4aa0-91a8-29adc1bf3f81",
   "metadata": {},
   "source": [
    "The following code is tested and implemented on the glaciers of [**Hans Tausen iskappe** of **Greenland**]\n",
    "\n",
    "---\n",
    "[**Hans Tausen iskappe** of **Greenland**]:https://en.wikipedia.org/wiki/Hans_Tausen_Ice_Cap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7e96c4-9235-4603-94c2-77942b1c31d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Import of important libraries\n",
    "- [os] module provides a portable way of using operating system dependent functionality. <br>\n",
    "- [numpy] library help to work with the array data. <br>\n",
    "- modules from [matplotlib] libraru used for visualize and plot the maps and graphs <b>\n",
    "- [scipy] is free open source python library used for scientific and technical computing <b>\n",
    "- [PIL] is Python Image Library helps to open, manipulate and save different image file format. <b>    \n",
    "\n",
    "\n",
    "[os]: https://github.com/python/cpython/blob/3.10/Lib/os.py\n",
    "[numpy]:https://github.com/numpy/numpy\n",
    "[matplotlib]:https://github.com/matplotlib/matplotlib\n",
    "[scipy]: https://github.com/scipy/scipy\n",
    "[PIL]: https://github.com/whatupdave/pil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581efa1f",
   "metadata": {},
   "source": [
    "first we need to import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f5ec60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libraries\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import ndimage\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c6b3f9-02bf-4795-aef0-34be0fdc624b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The following eratosthenes scientific library is written by [dr. Bas Altena] and his team for the focused purpose of image processing and GIS data handling during cryosphere studies but it can be used in different domain.  \n",
    "[dr. Bas Altena]: https://webspace.science.uu.nl/~alten005/\n",
    "\n",
    "- **[mapping_io]** library is the combination of different functions which helps to work with geotiff file. <br> Such as <br>:**read_geo_image**: takes as input the geotiff name and the path of the folder that the images are stored, reads the image and returns the data as an array <br> : **read_geo_info**: reads the geographic information of the image<br> : **make_geo_im**: Create georeferenced tiff file <br>\n",
    "[mapping_io]:https://github.com/GO-Eratosthenes/dhdt/blob/master/dhdt/generic/mapping_io.py\n",
    "[genric]: https://github.com/GO-Eratosthenes/dhdt/tree/master/dhdt/generic\n",
    "\n",
    "- **[mapping_tools]** library contains functions which helps to transform the image coordinates. <br> Some interesting functions are <br>: **pix_centers**provide the pixel coordinate from the axis, or the whole grid <br> : **vel2pix** transform map displacements to local image displacements. <br>\n",
    "[mapping_tools]: https://github.com/GO-Eratosthenes/dhdt/blob/master/dhdt/generic/mapping_tools.py\n",
    "\n",
    "- **[handler_im]** is combination of important functions which helps to perform enhancement to the image like, different image filtering, matrix transformation, image resizing etc. <br>\n",
    "Few examples from this library is as follows<br> :**get_grad_filters** constructs the gradient filters, parameters can be changed by defining different filter name such as sobel (default), kroon, schar, robinson, kayyali etc.<br>:**rescale_image** generate a zoomed-in version of an image, through isotropic scaling. <br>\n",
    "[handler_im]:https://github.com/GO-Eratosthenes/dhdt/blob/master/dhdt/generic/handler_im.py\n",
    "\n",
    "- **[gis_tools]** helps to work with different GIS (Geographic Information System) files and perform some functions like conversion of vector file into raster file, reproject the coordinates of shapefiles <br> Important functions are <br> :**get_mask_boundary** mask the image according the shapefile <br> :**shape2raster** converts shapefile into the raster <br>\n",
    "[gis_tools]:https://github.com/GO-Eratosthenes/dhdt/blob/master/dhdt/generic/gis_tools.py\n",
    "\n",
    "- **[image_transforms]** is combination of different functions, able to perform image pre-processing steps, such as transforming image intensities, transform image to have uniform distributions etc. <br> :**gamma_adjustment** able to transform image intensity in non-linear way<br> :**mat_to_gray** transform matrix array  to float, and also able to omit the nodata values <br>\n",
    "[image_transforms]:https://github.com/GO-Eratosthenes/dhdt/blob/master/dhdt/preprocessing/image_transforms.py\n",
    "\n",
    "- **[shadow_filters]** is majorly helps into shadow transformation and different methods can be implemented one by one. <br> <!---Such as <br>\"\"\" </b ---> :**anistropic_diffusion_scalar** can be implemented for non-linear anistropic diffusion filter of a scalar field <br>\n",
    "[shadow_filters]: https://github.com/GO-Eratosthenes/dhdt/blob/master/dhdt/preprocessing/shadow_filters.py\n",
    "\n",
    "- **[displacement_filters]** is specifically designed for the purpose of working with ice-velocity <br> :**local_infilling_filter** statistical local variance, based on the procedure <br> \n",
    "[displacement_filters]:https://github.com/GO-Eratosthenes/dhdt/blob/master/dhdt/postprocessing/displacement_filters.py\n",
    "\n",
    "- **[terrain_tools]** helps to perform rule sets using terrain information such as direction, offsets etc. <br> :**d8_flow** is unique function which evaluate the flow in all direction using X and y velocity of the glacier <br> :**curvature_enhanced_shading** help to visualize the curvature by combine single illumination shading with slope shading <br>\n",
    "[terrain_tools]:https://github.com/GO-Eratosthenes/dhdt/blob/master/dhdt/postprocessing/terrain_tools.py \n",
    "\n",
    "- **[image_io]** is designed for result visualization after image processing and export in interactive form<br> :**output_image** export and save the figure view <br> :**output_mask** export and save the figure after masking the some extent<br>\n",
    "[image_io]:https://github.com/GO-Eratosthenes/dhdt/blob/master/dhdt/presentation/image_io.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5a1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from specific libraries\n",
    "from eratosthenes.generic.mapping_io import \\\n",
    "    read_geo_image, read_geo_info, make_geo_im\n",
    "from eratosthenes.generic.mapping_tools import \\\n",
    "    pix_centers\n",
    "from eratosthenes.generic.handler_im import get_grad_filters\n",
    "from eratosthenes.generic.gis_tools import get_mask_boundary\n",
    "from eratosthenes.preprocessing.image_transforms import \\\n",
    "    gamma_adjustment, mat_to_gray\n",
    "from eratosthenes.preprocessing.shadow_filters import \\\n",
    "    anistropic_diffusion_scalar\n",
    "from eratosthenes.postprocessing.displacement_filters import \\\n",
    "    local_infilling_filter\n",
    "from eratosthenes.postprocessing.terrain_tools import d8_flow\n",
    "from eratosthenes.presentation.terrain_tools import curvature_enhanced_shading\n",
    "from eratosthenes.presentation.image_io import output_image, output_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb1a58c-0966-4cd7-a88b-e2f7b3df26a5",
   "metadata": {},
   "source": [
    "<font size=\"3\"> **Implementation and examination of the code on the study area [Hans Tausen iskappe of Greenland]** </font> <br>\n",
    "The data is situated on a **[drive]**, but these can be downloaded to a local drive. Hence the following code sniplet looks if such data is already available, if not it is downloaded.\n",
    "\n",
    "[Hans Tausen iskappe of Greenland]:https://goo.gl/maps/CRUj9nmeX8rN1gJLA\n",
    "[drive]: https://surfdrive.surf.nl/files/index.php/s/qebmYP7idEW89O0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c971a-775e-46fa-85f8-efbd158af90b",
   "metadata": {},
   "source": [
    "<font size=\"3\"> **Data description**</font> </br>\n",
    "- **a) Velocity** <br> The velocity data in this research project is obtained from the freely available open source **[CCI data]**. Velocity of Greenland Ice Sheet derived from Sentinel-1 descending and ascending SAR data, using InSAR and offset tracking method. This data was acquired during the winter campaigns between December 2018 and January 2021. InSAR derived velocity is available in NetCDF format with different products as separate layers, which is as follows: <br>\n",
    "i.\tAbsolute Velocity <br>\n",
    "ii.\tVertical Velocity <br>\n",
    "iii.\tHorizontal Velocity (East) <br>\n",
    "iv.\tVertical velocity (North) <br>\n",
    "v.\tUncertainty (based on Std.) (East) <br>\n",
    "vi.\tUncertainty (based on Std.) (North) <br>\n",
    "vii.\tPixel count <br>\n",
    "- **b) Glacier Boundary** <br> We downloaded the glacier boundary from the RGI open source day. Randolph Glacier Inventory(RGI) is extended mission of Global Land and Ice Measurement from Space (GLIMS) global glacier inventory. RGI database is being updated time to time, presently it in its 6th version. RGI is collaborative project among different research institution and universities. S\n",
    "- **c) Digital Elevation Model** <br> ArcticDEM of 100m of spatial resolution is used in this research, which is generated using stereo pair images, of WorldView series of the optical sensor satellite. Spatially it covers all land from 60Â°N. Later on the small DEM is cropped according to the spatial extend of the study area. \n",
    "[CCI data]:http://products.esa-icesheets-cci.org/products/details/greenland_iv_100m_s1_insar_s20181201_e20210301_v1.0.zip/\n",
    "\n",
    "<u>References: <br></u>\n",
    "http://products.esa-icesheets-cci.org/products/downloadlist/IV/ <br>\n",
    "Greenland Ice Sheet InSAR velocity map from Sentinel-1, winter campaigns 2018/2019- 2019/2020- 2020/2021 [version 1.0]\n",
    "RGI Consortium, 2017. Randolph Glacier Inventory - A Dataset of Global Glacier Outlines, Version 6. [Indicate subset used]. Boulder, Colorado USA. NSIDC: National Snow and Ice Data Center. doi: https://doi.org/10.7265/4m1f-gd79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f2299a4-6317-4c01-aeed-6dcafc5ccd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# admin\n",
    "dat_dir = \"icedivide\"\n",
    "dat_url = 'https://surfdrive.surf.nl/files/index.php/s/qebmYP7idEW89O0'\n",
    "\n",
    "vel_name = 'greenlan_iv_100m_s1_insar_s20181201_e20210301_v1_'\n",
    "v_x_name, v_y_name = 'east_velo.tif', 'north_velo.tif'\n",
    "v_x_std, v_y_std = 'east_std.tif', 'north_std.tif'\n",
    "v_count = 'count.tif'\n",
    "rgi_name = 'glacier_ids.tif'\n",
    "dem_name = 'arcticdem_100m.tif'\n",
    "velocity = 'abs_velo.tif'\n",
    "\n",
    "# # do downloading if files are not present\n",
    "# if not os.path.exists(os.path.join(dat_dir, rgi_name)):\n",
    "#     file_grab = urllib.URLopener()\n",
    "#     print('busy downloading files')\n",
    "#     # dowload velocity data\n",
    "#     file_grab.retrieve(os.path.join(dat_url, vel_name + v_x_name),\n",
    "#                        os.path.join(dat_dir, vel_name + v_x_name))\n",
    "#     file_grab.retrieve(os.path.join(dat_url, vel_name + v_y_name),\n",
    "#                        os.path.join(dat_dir, vel_name + v_y_name))\n",
    "#     file_grab.retrieve(os.path.join(dat_url, vel_name + v_x_std),\n",
    "#                        os.path.join(dat_dir, vel_name + v_x_std))\n",
    "#     file_grab.retrieve(os.path.join(dat_url, vel_name + v_y_std),\n",
    "#                        os.path.join(dat_dir, vel_name + v_y_std))\n",
    "#     file_grab.retrieve(os.path.join(dat_url, vel_name + v_count),\n",
    "#                        os.path.join(dat_dir, vel_name + v_count))\n",
    "#     # download auxillary data\n",
    "#     file_grab.retrieve(os.path.join(dat_url, rgi_name),\n",
    "#                        os.path.join(dat_dir, rgi_name))\n",
    "#     file_grab.retrieve(os.path.join(dat_url, dem_name),\n",
    "#                        os.path.join(dat_dir, dem_name))\n",
    "#     print('files dowloaded')\n",
    "# else:\n",
    "#     print('files are already present')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27209e8b-bb94-4d9b-b0f2-38520baf394c",
   "metadata": {},
   "source": [
    "import rasters with glacier polygons (RGI) and elevation (Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c7fffd8-0523-4a94-8aae-cd98c7f61efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatialRef, geoTransform,_,_,_,_ = read_geo_info(\n",
    "    os.path.join(dat_dir, rgi_name))\n",
    "RGI = read_geo_image(os.path.join(dat_dir, rgi_name))[0]\n",
    "Z = read_geo_image(os.path.join(dat_dir, dem_name))[0]\n",
    "RGI[RGI==1], Z[Z==-9999] = 0, np.nan\n",
    "X,Y = pix_centers(geoTransform, Z.shape[0], Z.shape[1], make_grid=True)\n",
    "spac = np.sqrt(np.sum(np.asarray(geoTransform[1:3])**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69054c-7e74-473d-a5f2-95fea09fac3d",
   "metadata": {},
   "source": [
    "import velocity products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8e7113e-1b6e-4575-a947-b8c1ca42b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_x = read_geo_image(os.path.join(dat_dir, vel_name + v_x_name))[0]\n",
    "V_y = read_geo_image(os.path.join(dat_dir, vel_name + v_y_name))[0]\n",
    "V_x_std = read_geo_image(os.path.join(dat_dir, vel_name + v_y_std))[0]\n",
    "V_y_std = read_geo_image(os.path.join(dat_dir, vel_name + v_y_std))[0]\n",
    "V_count = read_geo_image(os.path.join(dat_dir, vel_name + v_count))[0]\n",
    "V_vel = read_geo_image(os.path.join(dat_dir, vel_name + velocity))[0]\n",
    "\n",
    "NaN_val = V_x[0][0]\n",
    "V_x[V_x==NaN_val], V_y[V_y==NaN_val] = np.nan, np.nan\n",
    "V_x_std[V_x_std==NaN_val], V_y_std[V_y_std==NaN_val] = np.nan, np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7c5c4-6edd-447f-87f7-36c266d7e7bc",
   "metadata": {},
   "source": [
    "make topographic gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d20a03a4-e178-4cf7-90a3-79df098b22d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fx,fy = get_grad_filters(ftype='kroon', tsize=3, order=1)\n",
    "Z_x, Z_y = ndimage.convolve(Z, fx), ndimage.convolve(Z, fy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15526c1-2fd7-4389-9c1a-14f0818ffe7a",
   "metadata": {},
   "source": [
    "filling of the velocity field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6d7ebe-e061-4b7d-8440-6a2c82759efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_x_fill = local_infilling_filter(V_x, tsize=13)\n",
    "V_y_fill = local_infilling_filter(V_y, tsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a3938-8aea-4882-ae82-d13973162a67",
   "metadata": {},
   "source": [
    "cleaning of the velocity field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c122a188-015e-46f5-a01d-5c40e50476b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_clean = anistropic_diffusion_scalar(np.dstack((V_x_fill, V_y_fill)), iter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd658a3c-d459-4a8e-a297-d8426c921f04",
   "metadata": {},
   "source": [
    "d8 implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e452f8-b486-44cd-8ddd-c0a50c718e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RGI_new = d8_flow(RGI, -1*V_clean[:,:,0], +1*V_clean[:,:,1], iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc884fd-ad1c-4a24-a4e2-5fc0ff50224e",
   "metadata": {},
   "source": [
    "Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3749795e-8434-4377-a009-32016dbb031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eratosthenes.processing.matching_tools_frequency_metrics import \\\n",
    "    local_coherence\n",
    "\n",
    "# # divergence\n",
    "Div_clean = np.gradient(V_clean[:, :, 0])[0] + np.gradient(V_clean[:, :, 1])[1]\n",
    "Div_log = np.abs(Div_clean)  # np.log10(np.abs(Div_clean))\n",
    "Div_sgn = np.sign(Div_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a718935f-056a-4482-96c5-c40bee9ece0a",
   "metadata": {},
   "source": [
    "Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e3cc6aa-9c7b-4494-bd2a-46bf2eee605d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22500/3748033011.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  V_unit = np.divide(V_clean, np.tile(V_abs[:, :, np.newaxis], (1, 1, 2)))\n"
     ]
    }
   ],
   "source": [
    "V_abs = np.sqrt(V_clean[:, :, 0]**2 + V_clean[:, :, 1]**2)\n",
    "V_unit = np.divide(V_clean, np.tile(V_abs[:, :, np.newaxis], (1, 1, 2)))\n",
    "V_e = V_unit[:, :, 0] + 1j*V_unit[:, :, 1]\n",
    "# V_e = V_clean[:, :, 0] + 1j*V_clean[:, :, 1]\n",
    "Coherence = local_coherence(V_e, ds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36838b2b-7da5-4194-8ee3-af9b46e48f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Abs_Velocity = np.sqrt(V_clean[:, :, 0]**2 + V_clean[:, :, 1]**2)\n",
    "Magnitutde = np.sqrt(V_x_fill**2 + V_y_fill**2)\n",
    "Orientation = np.arctan2(V_x_fill, V_y_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbd35880-6ce0-4663-bb3f-c6b8acecb596",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coherence_Norm = np.log10(Coherence)\n",
    "Abs_Velocity_Norm = Abs_Velocity\n",
    "Magnitutde_Norm = Magnitutde\n",
    "Orientation_Norm = Orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d37932-f0b9-4bdd-be0e-29d15bd55213",
   "metadata": {},
   "source": [
    "Saving the output geotiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cdad2bf-bad6-4f65-830b-6b5f6acc9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_geo_im(Coherence_Norm.astype('float64'), geoTransform, spatialRef, \"Coherence_2504.tif\")\n",
    "make_geo_im(Abs_Velocity_Norm.astype('float64'), geoTransform, spatialRef, \"Abs_Velocity_2504.tif\")\n",
    "make_geo_im(Magnitutde_Norm.astype('float64'), geoTransform, spatialRef, \"Magnitutde_2504.tif\")\n",
    "make_geo_im(Orientation_Norm.astype('float64'), geoTransform, spatialRef, \"Orientation_2504.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca942c87-d357-4c38-bc1a-8ade65b54425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
